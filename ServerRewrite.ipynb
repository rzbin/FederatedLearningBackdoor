{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_COUNT = 3\n",
    "ROUNDS = 10\n",
    "\n",
    "SERVER_ADRESS = \"tcp://*:5555\"\n",
    "PUBLISHING_ADRESS = \"tcp://*:5557\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zmq\n",
    "import time\n",
    "import zmq\n",
    "import pickle\n",
    "import math\n",
    "import base64\n",
    "\n",
    "# Helpers\n",
    "\n",
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])\n",
    "\n",
    "def elapsed_time_total(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Total Training Time: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "                .format(int(hours),int(minutes),seconds))\n",
    "\n",
    "def elapsed_time_avg(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(\"Averaging overhead: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "                .format(int(hours),int(minutes),seconds))\n",
    "\n",
    "def write_data(file_name, data):\n",
    "    if type(data) == bytes:\n",
    "        #bytes to base64\n",
    "        data = base64.b64encode(data)\n",
    "         \n",
    "    with open(file_name, 'wb') as f: \n",
    "        f.write(data)\n",
    " \n",
    "def read_data(file_name):\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    #base64 to bytes\n",
    "    return base64.b64decode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_def import SimpleNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model_bytes):\n",
    "    import torch\n",
    "    import torchvision\n",
    "\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "    # Load the test dataset\n",
    "    testset = torchvision.datasets.MNIST(\"MNIST_data/\", train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model = pickle.loads(model_bytes)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the test images: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.ROUTER)\n",
    "socket.bind(SERVER_ADRESS)\n",
    "pub_socket = context.socket(zmq.PUB)\n",
    "pub_socket.bind(PUBLISHING_ADRESS)\n",
    "print(\"Context created\")\n",
    "\n",
    "\n",
    "start_total = time.time()\n",
    "\n",
    "print(\"The server is running now!\")\n",
    "\n",
    "model = SimpleNN()\n",
    "last_model = model\n",
    "\n",
    "all_models = []\n",
    "\n",
    "round_index = 0\n",
    "for i in range(ROUNDS * CLIENT_COUNT):\n",
    "    identifier, message = socket.recv_multipart()\n",
    "    print(f\"Received request from {identifier}\")\n",
    "\n",
    "    if message == b\"New\":\n",
    "        print(\"New client connected, sending model\")\n",
    "        toSend = pickle.dumps(model)\n",
    "        socket.send_multipart([identifier, toSend])\n",
    "        print(f\"Model sent\")\n",
    "    else:\n",
    "        print(f\"Received model from client\")\n",
    "        received_model = pickle.loads(message)\n",
    "        all_models.append(received_model)\n",
    "\n",
    "        print(f\"Have models: {len(all_models)}/{CLIENT_COUNT}\")\n",
    "        if len(all_models) == CLIENT_COUNT:\n",
    "            print(f\"Averaging models (round {round_index}/{ROUNDS})\")\n",
    "            start_avg = time.time()\n",
    "\n",
    "            # Learning rate from How to Backdoor paper (n / m, but we say m = n, so eta = 1)\n",
    "            n = CLIENT_COUNT\n",
    "            m = CLIENT_COUNT\n",
    "            eta = n / m\n",
    "\n",
    "            # Get a model with all 0's\n",
    "            averaged_model = SimpleNN()\n",
    "            for avg_param in averaged_model.parameters():\n",
    "                avg_param.data *= 0\n",
    "            # G^t+1 = G^t\n",
    "            for (avg_param, last_param) in zip(averaged_model.parameters(), last_model.parameters()):\n",
    "                avg_param.data += last_param.data\n",
    "            # Summation term\n",
    "            for model in all_models:\n",
    "                # G^t+1 += Sum( (eta / n) * (L^t+1_i - G^t) )\n",
    "                # for (G^t+1, G^t, L^t+1_i) in ...\n",
    "                for (avg_param, last_param, local_param) in zip(averaged_model.parameters(), last_model.parameters(), model.parameters()):\n",
    "                    avg_param.data += (eta / n) * (local_param.data - last_param.data)\n",
    "                    \n",
    "            all_models = []\n",
    "\n",
    "            end_avg = time.time()\n",
    "            elapsed_time_avg(start_avg, end_avg)\n",
    "\n",
    "            last_model = averaged_model\n",
    "\n",
    "            print(f\"Sending averaged model (round {round_index}/{ROUNDS})\")\n",
    "            toSend = pickle.dumps(averaged_model)\n",
    "            pub_socket.send(toSend)\n",
    "            print(f\"Averaged model sent (round {round_index}/{ROUNDS})\")\n",
    "            round_index += 1\n",
    "            # Print current model accuracy\n",
    "            test_model(pickle.dumps(last_model))\n",
    "\n",
    "end_total = time.time()\n",
    "elapsed_time_total(start_total, end_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_model(pickle.dumps(last_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pickle\n",
    "\n",
    "def test_model_by_label(model_bytes):\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    # Load the test dataset\n",
    "    testset = torchvision.datasets.MNIST(\"MNIST_data/\", train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "    # Set the model to evaluation mode\n",
    "    model = pickle.loads(model_bytes)\n",
    "    model.eval()\n",
    "\n",
    "    label_counts = {}  # Dictionary to store the count of predictions for each label\n",
    "    for i in range(10):\n",
    "        label_counts[i] = [0] * 10\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                true_label = labels[i].item()\n",
    "                predicted_label = predicted[i].item()\n",
    "                # print(f\"Label: {true_label}, Predicted: {predicted_label}. \")\n",
    "                label_counts[true_label][predicted_label] += 1\n",
    "        \n",
    "        for true_label, counts in label_counts.items():\n",
    "            print(f\"True Label: {true_label}\")\n",
    "            for predicted_label, count in enumerate(counts):\n",
    "                percentage = count / sum(counts) * 100\n",
    "                print(f\"  Predicted {predicted_label}: {percentage:.2f}%\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "test_model_by_label(pickle.dumps(last_model))\n",
    "test_model(pickle.dumps(last_model))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
